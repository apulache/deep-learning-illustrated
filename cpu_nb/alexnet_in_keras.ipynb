{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we leverage an [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)-like deep, convolutional neural network to classify flowers into the 17 categories of the [Oxford Flowers](http://www.robots.ox.ac.uk/~vgg/data/flowers/17/) data set. Derived from [this earlier notebook](https://github.com/the-deep-learners/TensorFlow-LiveLessons/blob/master/notebooks/old/L3-3b__TFLearn_AlexNet.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/alexnet_in_keras.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 2)) (2.11.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gensim\n",
      "  Downloading gensim-4.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 8)) (8.0.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 9)) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r /workspace/requirements.txt (line 10)) (3.6.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tflearn->-r /workspace/requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tflearn->-r /workspace/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from tflearn->-r /workspace/requirements.txt (line 1)) (9.4.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->-r /workspace/requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->-r /workspace/requirements.txt (line 4)) (4.64.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r /workspace/requirements.txt (line 4)) (8.1.3)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim->-r /workspace/requirements.txt (line 5)) (1.10.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym->-r /workspace/requirements.txt (line 6)) (2.2.1)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r /workspace/requirements.txt (line 8)) (4.0.5)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r /workspace/requirements.txt (line 8)) (8.8.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r /workspace/requirements.txt (line 8)) (6.20.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r /workspace/requirements.txt (line 8)) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->-r /workspace/requirements.txt (line 8)) (5.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /workspace/requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r /workspace/requirements.txt (line 9)) (2022.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r /workspace/requirements.txt (line 10)) (1.0.7)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (6.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (1.5.6)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (25.0.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (7.4.9)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (1.6.6)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.1.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.1.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (5.9.4)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (2.14.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (3.0.36)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (5.1.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.18.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (5.1.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.2.6)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r /workspace/requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r /workspace/requirements.txt (line 8)) (2.6.2)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim->-r /workspace/requirements.txt (line 5)) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->-r /workspace/requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->-r /workspace/requirements.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->-r /workspace/requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim->-r /workspace/requirements.txt (line 5)) (1.26.14)\n",
      "Building wheels for collected packages: tflearn, gym, fst-pso, miniful\n",
      "  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127283 sha256=114921849c3df35bd8f38e09cee22b44ab7c2e8a0234cac35bd429613cab1d91\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5d/83/f7/63e33ac9c0560f1dddb2ecff627b8ab6cb076d4b1996416be1\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827630 sha256=ea2d69939647a47db96f736bc604cd85ea12212be3f7e0df91b0c1a5312fa74f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/ae/5f/67/64914473eb34e9ba89dbc7eefe7e9be8f6673fbc6f0273b29f\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=9621f93b1d9d6604d159b449e36dcd2781a49127b6576a11a7bde65868c0b6dd\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/01/02/ee/df0699282986903a384b69aab4413af9efd26b3612b5dccc9e\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3513 sha256=5c68162d55181aa245fd5d59f22650ede7567996853c96be7aafc959a321c0c7\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/43/aa/48/5c66b931ff013ad19774081aa19656637af5c0cc33b5494b30\n",
      "Successfully built tflearn gym fst-pso miniful\n",
      "Installing collected packages: gym-notices, tflearn, smart-open, regex, gym, simpful, nltk, miniful, fst-pso, pyfume, FuzzyTM, gensim\n",
      "Successfully installed FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 gym-0.26.2 gym-notices-0.0.8 miniful-0.0.6 nltk-3.8.1 pyfume-0.2.25 regex-2022.10.31 simpful-2.9.0 smart-open-6.3.0 tflearn-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r /workspace/requirements_cpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 23:16:46.509885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#import keras   for Jetson\n",
    "#from keras.models import Sequential # For Jetson\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D # For Jetson\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "#from keras.layers.normalization import BatchNormalization # For Jetson\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load *and preprocess* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 26, 26, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10, 10, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 384)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1, 1, 384)        1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              1576960   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 17)                69649     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,883,153\n",
      "Trainable params: 21,881,681\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.9563 - acc: 0.5000 - val_loss: 5.4127 - val_acc: 0.2353\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.6974 - acc: 0.5441 - val_loss: 4.6127 - val_acc: 0.2279\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.7619 - acc: 0.4975 - val_loss: 3.3280 - val_acc: 0.3456\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.6082 - acc: 0.5907 - val_loss: 3.6455 - val_acc: 0.3162\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.5566 - acc: 0.5980 - val_loss: 2.5124 - val_acc: 0.4706\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.7667 - acc: 0.5441 - val_loss: 4.7255 - val_acc: 0.3235\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.6807 - acc: 0.5686 - val_loss: 4.3251 - val_acc: 0.3603\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.4391 - acc: 0.6144 - val_loss: 2.9430 - val_acc: 0.4191\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.2114 - acc: 0.6528 - val_loss: 3.9192 - val_acc: 0.3456\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.3771 - acc: 0.6511 - val_loss: 2.4197 - val_acc: 0.4779\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.3751 - acc: 0.6283 - val_loss: 3.3495 - val_acc: 0.4118\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.2065 - acc: 0.6552 - val_loss: 3.2084 - val_acc: 0.3897\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.1327 - acc: 0.6814 - val_loss: 3.3864 - val_acc: 0.3971\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.1448 - acc: 0.6863 - val_loss: 2.5669 - val_acc: 0.4779\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.1225 - acc: 0.6658 - val_loss: 2.6759 - val_acc: 0.4926\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 1.6822 - acc: 0.5801 - val_loss: 2.8494 - val_acc: 0.4265\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.3445 - acc: 0.6511 - val_loss: 3.0909 - val_acc: 0.4118\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.1837 - acc: 0.6944 - val_loss: 3.5750 - val_acc: 0.4706\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 1.1290 - acc: 0.6789 - val_loss: 3.1716 - val_acc: 0.4559\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 16s 13ms/sample - loss: 1.1347 - acc: 0.7116 - val_loss: 2.9057 - val_acc: 0.4412\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 16s 13ms/sample - loss: 1.2651 - acc: 0.6863 - val_loss: 3.1673 - val_acc: 0.4779\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.8450 - acc: 0.7647 - val_loss: 2.6484 - val_acc: 0.5368\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.6924 - acc: 0.7721 - val_loss: 2.6172 - val_acc: 0.5294\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.7462 - acc: 0.7810 - val_loss: 2.2605 - val_acc: 0.5882\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.7400 - acc: 0.7908 - val_loss: 3.3980 - val_acc: 0.5294\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6936 - acc: 0.8170 - val_loss: 3.9773 - val_acc: 0.4485\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6011 - acc: 0.8154 - val_loss: 2.7314 - val_acc: 0.5074\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6030 - acc: 0.8170 - val_loss: 2.3035 - val_acc: 0.6029\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6052 - acc: 0.8374 - val_loss: 3.0819 - val_acc: 0.5588\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.8358 - acc: 0.7884 - val_loss: 3.3894 - val_acc: 0.4412\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6284 - acc: 0.8064 - val_loss: 3.0367 - val_acc: 0.5294\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.5975 - acc: 0.8260 - val_loss: 3.8116 - val_acc: 0.4118\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.7121 - acc: 0.8023 - val_loss: 2.9502 - val_acc: 0.5221\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.7886 - acc: 0.7925 - val_loss: 2.6474 - val_acc: 0.5221\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.7751 - acc: 0.7835 - val_loss: 3.4675 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.7113 - acc: 0.8121 - val_loss: 3.0872 - val_acc: 0.5441\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.8089 - acc: 0.8056 - val_loss: 3.0571 - val_acc: 0.5294\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.7818 - acc: 0.7933 - val_loss: 3.4005 - val_acc: 0.5147\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.5335 - acc: 0.8497 - val_loss: 4.2025 - val_acc: 0.4412\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4383 - acc: 0.8709 - val_loss: 3.2063 - val_acc: 0.4853\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3499 - acc: 0.8930 - val_loss: 3.0268 - val_acc: 0.6029\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.8353 - acc: 0.7990 - val_loss: 2.9203 - val_acc: 0.5147\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.5321 - acc: 0.8456 - val_loss: 2.2814 - val_acc: 0.6397\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 16s 13ms/sample - loss: 0.2983 - acc: 0.9077 - val_loss: 2.8825 - val_acc: 0.5588\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2489 - acc: 0.9265 - val_loss: 3.2463 - val_acc: 0.5441\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.7167 - acc: 0.8342 - val_loss: 4.4375 - val_acc: 0.4485\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.6666 - acc: 0.8350 - val_loss: 3.5122 - val_acc: 0.5074\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4135 - acc: 0.8873 - val_loss: 3.6567 - val_acc: 0.5074\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.6457 - acc: 0.8636 - val_loss: 3.8362 - val_acc: 0.4559\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4132 - acc: 0.8807 - val_loss: 7.5656 - val_acc: 0.2941\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.3428 - acc: 0.8971 - val_loss: 4.6766 - val_acc: 0.4706\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4397 - acc: 0.8913 - val_loss: 4.1780 - val_acc: 0.5441\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4211 - acc: 0.8913 - val_loss: 4.1178 - val_acc: 0.4779\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3643 - acc: 0.9077 - val_loss: 3.5140 - val_acc: 0.5588\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3313 - acc: 0.9093 - val_loss: 3.2691 - val_acc: 0.5368\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4236 - acc: 0.8873 - val_loss: 3.1204 - val_acc: 0.5588\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4264 - acc: 0.8889 - val_loss: 3.9854 - val_acc: 0.5294\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 16s 13ms/sample - loss: 0.1966 - acc: 0.9371 - val_loss: 3.7319 - val_acc: 0.5441\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.5067 - acc: 0.8758 - val_loss: 5.3004 - val_acc: 0.4853\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.4964 - acc: 0.8824 - val_loss: 4.5932 - val_acc: 0.4779\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3276 - acc: 0.9265 - val_loss: 3.3822 - val_acc: 0.5809\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1663 - acc: 0.9485 - val_loss: 3.4104 - val_acc: 0.5735\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1315 - acc: 0.9583 - val_loss: 3.1688 - val_acc: 0.5956\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.1490 - acc: 0.9502 - val_loss: 2.9106 - val_acc: 0.6324\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 15s 13ms/sample - loss: 0.1584 - acc: 0.9616 - val_loss: 3.6619 - val_acc: 0.6324\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1243 - acc: 0.9567 - val_loss: 3.6359 - val_acc: 0.6397\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1910 - acc: 0.9551 - val_loss: 3.0536 - val_acc: 0.6029\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1846 - acc: 0.9567 - val_loss: 6.5052 - val_acc: 0.4191\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4393 - acc: 0.8913 - val_loss: 4.4448 - val_acc: 0.5074\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.6307 - acc: 0.8652 - val_loss: 3.8450 - val_acc: 0.5956\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4847 - acc: 0.8962 - val_loss: 3.7081 - val_acc: 0.6103\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2590 - acc: 0.9314 - val_loss: 4.3930 - val_acc: 0.5368\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4702 - acc: 0.8987 - val_loss: 5.4796 - val_acc: 0.4412\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4531 - acc: 0.8962 - val_loss: 4.1321 - val_acc: 0.5662\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4172 - acc: 0.8922 - val_loss: 3.7033 - val_acc: 0.5221\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3838 - acc: 0.8938 - val_loss: 4.3398 - val_acc: 0.5515\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1992 - acc: 0.9518 - val_loss: 3.6863 - val_acc: 0.5368\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0842 - acc: 0.9747 - val_loss: 3.0225 - val_acc: 0.6324\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0905 - acc: 0.9681 - val_loss: 3.1674 - val_acc: 0.6324\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2214 - acc: 0.9461 - val_loss: 3.8997 - val_acc: 0.6029\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2966 - acc: 0.9273 - val_loss: 4.0705 - val_acc: 0.5441\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2660 - acc: 0.9355 - val_loss: 3.5914 - val_acc: 0.6103\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0970 - acc: 0.9722 - val_loss: 3.5200 - val_acc: 0.6029\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0812 - acc: 0.9714 - val_loss: 3.3407 - val_acc: 0.5809\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1191 - acc: 0.9722 - val_loss: 3.9636 - val_acc: 0.5441\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0694 - acc: 0.9722 - val_loss: 3.3604 - val_acc: 0.6176\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0545 - acc: 0.9845 - val_loss: 3.8567 - val_acc: 0.5809\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1751 - acc: 0.9551 - val_loss: 3.9524 - val_acc: 0.6103\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1982 - acc: 0.9502 - val_loss: 4.3922 - val_acc: 0.6029\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1582 - acc: 0.9657 - val_loss: 3.4812 - val_acc: 0.6250\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.4916 - acc: 0.9011 - val_loss: 5.2647 - val_acc: 0.4926\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3135 - acc: 0.9240 - val_loss: 5.1467 - val_acc: 0.5441\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2234 - acc: 0.9387 - val_loss: 5.1596 - val_acc: 0.5368\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2001 - acc: 0.9526 - val_loss: 4.0057 - val_acc: 0.6397\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1544 - acc: 0.9559 - val_loss: 4.1022 - val_acc: 0.6397\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1688 - acc: 0.9567 - val_loss: 4.7920 - val_acc: 0.5662\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.2220 - acc: 0.9526 - val_loss: 4.6925 - val_acc: 0.5956\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.3007 - acc: 0.9355 - val_loss: 4.3196 - val_acc: 0.5662\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.1529 - acc: 0.9551 - val_loss: 4.6709 - val_acc: 0.5882\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 15s 12ms/sample - loss: 0.0892 - acc: 0.9747 - val_loss: 3.8163 - val_acc: 0.6324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27fdfeaa70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
